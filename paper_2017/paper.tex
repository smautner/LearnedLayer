\documentclass{article}
\begin{document}

\section{Method}

We \textbf{ aim }is to generate graphs that are functionally similar to a given set of graphs (seed graphs).
The Quality of a solution is determined by a machine learning method with a decomposition graph 
kernel applied to the given set. New instances are sampled by repeatedly applying productions
of a graph grammar on the seed graphs and accepting changes according to the score of the generated
instance (Markov Chain Monte Carlo - MCMC - sampling). The presented grammar will identify
active subgraphs in the given instances by a deep learning method to increase its potency. 
 
The \textbf{decomposition kernel}. A graph consists of vertices and edges $(V,E)$. 
A Label if a vertex can be accessed via a $label$ function .
The length of the shortest path between vertices $a,b \in V$ is given by $dist(a,b)$.
A neighborhood $N^r(v)$ of a
vertex $v$ is the subgraph induced by the vertices $\{dist(v,u) \leq r | u,v \in V \}$.
The kernel has two parameter $R$ and $D$ which it uses to decompose a graph into neighborhood pairs
$\{ (N^r(v), N^r(u)) | v,u \in V , dist(u,v) \leq d, r \in \{0,...,R\}, d\in \{0,...,D\}  \}$. 
Each such pair will be hashed and accounted for in the explicit feature vector.
Therefore  hashes match iff subgraph pairs are isomorphic.
For the following hashing scheme any hash function might be used e.g. any Merkle--Damgard construction.
Let $h$ be a function that orders its arguments lexicographically before applying a hash function. 
The hash of a neighborhood subgraph is $H((V,E)) = h(\{ h(label(u), label(v)) | u,v \in E \})$
and finally the neighborhood pair $(a,b)$ is hashed by $h(H(a),H(b))$.
We normalize for each $R \times D$ before normalizing the whole Vector to a unit vector.

The \textbf{GraphLearn} system. A new graph is generated by passing one of the seed graphs
through an MCMC scheme. MCMC is a technique to draw from a distribution by iterating over 
a state according to the underlying Markov chain probabilities. In this case a state is a 
graph and changes are applied repeatedly, we keep or discard the altered graph according
to the probability given by a model trained with the decomposition kernel. 

Applying random changes to a graph would result in a high rejection rate by the MCMC 
algorithm. Therefore we suggest new graphs by applying a \textbf{graph grammar}. 
A graph grammar is similar to a string grammar. A production has the form $(M,D,E)$ 
where $M$ and $D$ are graphs while $E$ is an embedding mechanism.
and is applied as follows. 
We consider M and D graphs as core-interface pairs with a root vertex. 
Core and interface are the disjoint subgraphs that make up the M and D graphs. 
The core $C^v_R(G)$ is a neighborhood graph $N^R(v)$ of $G$ with radius $R$ and root $v$.
An interface is denoted $I^v_{R,T}(G)$ it is the subgraph induced by the vertices $N^{R+T}(v) - 
N^{R}(v)$. Two core interface pairs are congruent iff 
their interfaces are isomorphic. The hashing function presented in another section 
of this work is also used here to reduce the cost of an isomorphism check. 
A production can be applied iff $M$ and $D$ are congruent. $E$ will consider the 
host graph $H$ of which $M$ is part and $D$ together. First the core of $M$ is removed,
then isomorphic vertices of the interfaces of $M$ and $D$ are merged.


\textbf{Identification of important region in a molecule} and how to use it in the GraphLearn
system. We estimate the importance of a vertex $n$ by the (normalized as above) feature vector 
obtained by all the neighborhood pairs of which $n$ is a root vertex and a model.
Vertices connected by an edge, whose importance score difference is below a threshold are considered
to be of the same region (because we use the difference, the intercept of the estimator can
be neglected). This relation is transitive. After extracting these regions from seeds, 
the regions are clustered by vectorizing them with EDeN and running DBSCAN. 
DBSCAN is a clustering algorithm that uses a distance parameter. We calculate the distances to the 
nearest neighbors of all regions and sort these distances. The DBSCAN range parameter is 
picked at a certain percentage of that list. 

We can now calculate an \textbf{abstracted graph} for each seed. 
First we determine the region and use the clustering model to obtain a cluster id
,edges within a region are contracted, a new graph is
obtained. Vertices affected by the contraction process are renamed to their cluster id.
We can repeat this process on the abstracted graphs to obtain another level (layer) of abstraction.

These new \textbf{layers can not be used in the GraphLearn system} as we presented it. 
Since vertices are either untouched or merged via an edge as one traverses the layers,
it is easy to see which vertices on the seed graphs $G$ belong to which vertices on the
top layer $G'$. With this knowledge in mind one can discard the in between layers; and 
we proceed with the modifications to the grammar.
Cores and interfaces can now be defined exploiting $G'$.
Starting from a CIP (Core Interface Pair) extracted from the coarser graph $G$, 
we define the core as the sub graph induced by the vertices of
the original graph that have been contracted to vertices of the core of radius
$R$ in the coarse graph, $C_R^v(G',G)$. The new interface graph
$I_{R,B}^v(G',G)$ is defined as the Cartesian product of the graph induced by
the nodes adjacent to the core nodes in $G$ at maximal distance $B$ (the
thickness in the base graph) and the interface graph on the coarse graph. In
words, we require that both the interface at base level and at coarse level
match for a core swap to take place.














\end{document}
