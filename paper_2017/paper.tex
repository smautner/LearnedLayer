\documentclass{article}
\begin{document}

\section{Method}

We \textbf{ aim }is to generate graphs that are functionally similar to a given set of graphs (seed graphs).
The Quality of a solution is determined by a machine learning method with a decomposition graph 
kernel applied to the given set. New instances are sampled by repeatedly applying productions
of a graph grammar on the seed graphs and accepting changes according to the score of the generated
instance (Markov Chain Monte Carlo - MCMC - sampling). The presented grammar will identify
active subgraphs in the given instances by a deep learning method to increase its potency. 
 
The \textbf{decomposition kernel}. A graph consists of vertives and edges $(V,E)$. 
A Label if a vertex can be accessed via a $label$ function .
The length of the shortest path between vertices $a,b \in V$ is given by $dist(a,b)$.
A neighborhood $N^r(v)$ of a
vertex $v$ is the subgraph induced by the vertices $\{dist(v,u) \leq r | u,v \in V \}$.
The kernel has two parameter $R$ and $D$ which it uses to decompose a graph into neighborhood pairs
$\{ (N^r(v), N^r(u)) | v,u \in V , dist(u,v) \leq d, r \in \{0,...,R\}, d\in \{0,...,D\}  \}$. 
Each such pair will be hashed and accounted for in the explicit feature vector.
Therefore  hashes match iff subgraph pairs are isomorphic.
For the folowing hashing sheme any hash function might be used e.g. any Merkle--Damgard construction.
Let $h$ be a function that orders its arguments lexocographicaly before applying a hash function. 
The hash of a neighborhood subgraph is $H((V,E)) = h(\{ h(label(u), label(v)) | u,v \in E \})$
and finaly the neighborhood pair $(a,b)$ is hashed by $h(H(a),H(b))$.
We normalize for each $R \times D$ before normalizing the whole Vector to a unit vector.

The \textbf{GraphLearn} system. A new graph is generated by passing one of the seed graphs
through an MCMC scheme. MCMC is a technique to draw from a distribution by iterating over 
a state according to the underlying markov chain probabilities. In this case a state is a 
graph and changes are applied repeatedly, we keep or discard the altered graph according
to the probability given by a model trained with the decomposition kernel. 

Applying random changes to a graph would result in a high rejection rate by the MCMC 
algorithm. Therefore we suggest new graphs by applying a \textbf{graph grammar}. 
A graph grammar is simmilar to a string grammar. A production has the form $(M,D,E)$ 
where $M$ and $D$ are graphs while $E$ is an embeding mechanism.
and is applied as follows. 
We consider M and D graphs as core-interface pairs with a root vertex. 
Core and interface are the disjoint subgraphs that make up the M and D graphs. 
The core $C^v_R(G)$ is a neighborhood graph $N^R(v)$ of $G$ with radius $R$ and root $v$.
An interface is denoted $I^v_{R,T}(G)$ it is the subgraph induced by the vertices $N^{R+T}(v) - 
N^{R}(v)$. Two core interaface pairs are congruent iff 
their interfaces are isomorphic. The hashing function presented in another section 
of this work is also used here to reduce the cost of an isomorphism check. 
A production can be applied iff $M$ and $D$ are congruent. $E$ will consider the 
host graph $H$ of which $M$ is part and $D$ together. First the core of $M$ is removed,
then isomorphic vertices of the interfaces of $M$ and $D$ are merged.



\end{document}
